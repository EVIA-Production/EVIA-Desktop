
import React, { useState, useEffect } from 'react';
import { Button } from '@/components/ui/button';
import { Link, useNavigate } from 'react-router-dom';
import EviaLogo from '@/components/EviaLogo';
import RecordingControls from '@/components/RecordingControls';
import TranscriptPanel from '@/components/TranscriptPanel';
import StatusIndicator from '@/components/StatusIndicator';
import { useToast } from '@/hooks/use-toast';
import { LogIn } from 'lucide-react';
import { useAuth } from '@/contexts/AuthContext';
import { chatService } from '@/services/chatService';

const Index = () => {
  const [isConnected, setIsConnected] = useState(false);
  const [hasAccessToken, setHasAccessToken] = useState(true);
  const [isRecording, setIsRecording] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [suggestion, setSuggestion] = useState('');
  const [debugLog, setDebugLog] = useState<string[]>([]);
  const [chatId, setChatId] = useState<string | null>(null);
  const { toast } = useToast();
  const { isAuthenticated } = useAuth();
  const navigate = useNavigate();
  
  // Add a debug logging function
  const addDebugLog = (message: string) => {
    setDebugLog(prev => [...prev, `[${new Date().toISOString()}] ${message}`]);
    console.log(`DEBUG: ${message}`);
  };
  
  useEffect(() => {
    console.log('Index component mounted');
    setIsConnected(true); // Set to connected by default since we're not using WebSockets
    
    // Redirect to login if not authenticated
    if (!isAuthenticated) {
      console.log('User not authenticated, redirecting to login');
      navigate('/login');
      return;
    }
    
    // Check for existing chat ID
    const existingChatId = chatService.getCurrentChatId();
    if (existingChatId) {
      setChatId(existingChatId);
      addDebugLog(`Using existing chat ID: ${existingChatId}`);
    } else {
      // Create a new chat when the user is authenticated
      const createNewChat = async () => {
        try {
          addDebugLog('Creating new chat session...');
          const newChatId = await chatService.createChat();
          setChatId(newChatId);
          addDebugLog(`Chat created successfully with ID: ${newChatId}`);
          toast({
            description: "Chat session created",
          });
        } catch (error) {
          console.error('Failed to create chat:', error);
          addDebugLog(`Failed to create chat: ${error instanceof Error ? error.message : String(error)}`);
          toast({
            title: "Error",
            description: "Failed to create chat session",
            variant: "destructive"
          });
        }
      };
      
      createNewChat();
    }
  }, [isAuthenticated, navigate, toast]);

  const handleStartRecording = async () => {
    console.log('handleStartRecording called');
    
    try {
      // Request both audio and screen capture permissions
      const audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const displayStream = await navigator.mediaDevices.getDisplayMedia({ 
        video: { 
          displaySurface: "monitor" 
        },
        audio: true 
      });
      
      // If we get here, permissions were granted
      setIsRecording(true);
      addDebugLog('Permissions granted. Recording started.');
      
      // Simulate transcription with some sample text
      setTimeout(() => {
        setTranscript('This is a sample transcript that would normally come from speech recognition.');
      }, 1000);
      
      // Clean up function to stop tracks when recording is stopped
      return () => {
        audioStream.getTracks().forEach(track => track.stop());
        displayStream.getTracks().forEach(track => track.stop());
      };
    } catch (error) {
      console.error('Error getting media permissions:', error);
      addDebugLog(`Permission error: ${error}`);
      toast({
        title: "Permission Error",
        description: "Could not access microphone or screen. Please grant permissions and try again.",
        variant: "destructive"
      });
    }
  };

  const handleStopRecording = () => {
    console.log('handleStopRecording called');
    setIsRecording(false);
    addDebugLog('Recording stopped');
    toast({
      description: "Recording stopped",
    });
  };

  const handleSuggest = () => {
    console.log('handleSuggest called');
    addDebugLog('Suggestion requested');
    toast({
      description: "Requesting suggestion...",
    });
    
    // Simulate a suggestion response
    setTimeout(() => {
      setSuggestion('This is a sample suggestion based on your transcript. In a real application, this would be generated by an AI based on the recorded speech.');
    }, 1000);
  };

  const handleResetContext = () => {
    console.log('handleResetContext called');
    setTranscript('');
    setSuggestion('');
    addDebugLog('Context reset');
    toast({
      description: 'Context has been reset',
    });
  };
  
  // If the redirect is happening, don't render the full content
  if (!isAuthenticated) {
    return <div>Redirecting to login...</div>;
  }
  
  return (
    <div className="min-h-screen bg-gradient-to-b from-black to-gray-900 text-white flex flex-col">
      {/* Header */}
      <header className="p-4 flex justify-between items-center border-b border-gray-800 bg-black bg-opacity-60 backdrop-blur-md">
        <EviaLogo className="text-white" />
        <div className="flex gap-3">
          <Link to="/login">
            <Button variant="outline" className="border-gray-600 hover:bg-gray-800 text-white">
              <LogIn className="mr-2 h-4 w-4" /> Sign In
            </Button>
          </Link>
          <Link to="/register">
            <Button variant="default" className="bg-evia-pink hover:bg-pink-700">
              Sign Up
            </Button>
          </Link>
        </div>
      </header>

      {/* Main Content */}
      <main className="flex-1 container mx-auto px-4 py-8 max-w-6xl">
        <h1 className="text-3xl md:text-4xl font-bold text-center mb-8 text-gradient-to-r from-pink-500 to-evia-pink">
          EVIA Live Transcription & Suggestions
        </h1>

        {/* Chat Status */}
        {chatId && (
          <div className="mb-4 text-center">
            <p className="text-green-400">Connected to chat session: {chatId.substring(0, 8)}...</p>
          </div>
        )}

        {/* Controls */}
        <div className="mb-8">
          <RecordingControls
            isRecording={isRecording}
            onStartRecording={handleStartRecording}
            onStopRecording={handleStopRecording}
            onSuggest={handleSuggest}
            onResetContext={handleResetContext}
            isConnected={isConnected && !!chatId}
          />
        </div>

        {/* Status */}
        <StatusIndicator 
          isConnected={isConnected} 
          hasAccessToken={hasAccessToken} 
        />

        {/* Transcription & Suggestion Panels */}
        <div className="grid grid-cols-1 md:grid-cols-2 gap-6 h-[500px]">
          <TranscriptPanel 
            title="Live Transcript" 
            content={transcript}
            placeholder="Waiting for speech..."
            className="bg-gray-900 bg-opacity-50 border border-gray-800 shadow-lg"
          />
          <TranscriptPanel 
            title="Suggestion" 
            content={suggestion}
            placeholder="Click 'Suggest' after speaking..."
            className="bg-gray-900 bg-opacity-50 border border-gray-800 shadow-lg"
          />
        </div>
      </main>
      
      {/* Footer */}
      <footer className="py-6 border-t border-gray-800 bg-black bg-opacity-60 backdrop-blur-md mt-8">
        <div className="container mx-auto text-center text-gray-400 text-sm">
          <p>Â© {new Date().getFullYear()} EVIA Voice Assistant. All rights reserved.</p>
        </div>
      </footer>
    </div>
  );
};

export default Index;
